[ Mon Oct 21 18:47:34 2024 ] using warm up, epoch: 5
[ Mon Oct 21 18:48:09 2024 ] using warm up, epoch: 5
[ Mon Oct 21 18:48:10 2024 ] Parameters:
{'work_dir': './mixformer_joint/work_dir', 'model_saved_name': './mixformer_joint/runs', 'config': './config_mixformer/mixformer_joint_train.yaml', 'device': 0, 'phase': 'train', 'save_score': True, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'dataset': 'datasets.dataset.UavDataset', 'num_workers': 0, 'train_data_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'debug': False, 'use_mmap': True, 'random_rot': False, 'p_interval': [0.5, 1], 'd': 2}, 'val_data_args': {'data_path': './data/test_A_joint.npy', 'label_path': './data/test_A_label.npy', 'debug': False, 'window_size': 64, 'p_interval': [0.95], 'd': 2}, 'test_data_args': {}, 'model': 'model.ske_mixf.Model', 'model_args': {'num_class': 155, 'num_point': 17, 'num_person': 2, 'graph': 'graph.uav.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.2, 'step': [20, 40, 60], 'nesterov': True, 'optimizer': 'SGD', 'batch_size': 32, 'val_batch_size': 256, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'lr_decay_rate': 0.1, 'weight_decay': 0.0005, 'only_train_part': False, 'only_train_epoch': 0, 'warm_up_epoch': 5}

[ Mon Oct 21 18:48:10 2024 ] Training epoch: 1
[ Mon Oct 21 18:56:32 2024 ] using warm up, epoch: 5
[ Mon Oct 21 18:56:33 2024 ] Parameters:
{'work_dir': './mixformer_joint/work_dir', 'model_saved_name': './mixformer_joint/runs', 'config': './config_mixformer/mixformer_joint_train.yaml', 'device': 0, 'phase': 'train', 'save_score': True, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'dataset': 'datasets.dataset.UavDataset', 'num_workers': 0, 'train_data_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'debug': False, 'use_mmap': True, 'random_rot': False, 'p_interval': [0.5, 1], 'd': 2}, 'val_data_args': {'data_path': './data/test_A_joint.npy', 'label_path': './data/test_A_label.npy', 'debug': False, 'window_size': 64, 'p_interval': [0.95], 'd': 2}, 'test_data_args': {}, 'model': 'model.ske_mixf.Model', 'model_args': {'num_class': 155, 'num_point': 17, 'num_person': 2, 'graph': 'graph.uav.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.2, 'step': [20, 40, 60], 'nesterov': True, 'optimizer': 'SGD', 'batch_size': 32, 'val_batch_size': 256, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'lr_decay_rate': 0.1, 'weight_decay': 0.0005, 'only_train_part': False, 'only_train_epoch': 0, 'warm_up_epoch': 5}

[ Mon Oct 21 18:56:33 2024 ] Training epoch: 1
[ Mon Oct 21 19:09:38 2024 ] 	Mean training loss: 5.0042.
[ Mon Oct 21 19:09:38 2024 ] Eval epoch: 1
[ Mon Oct 21 19:10:17 2024 ] 	Mean val loss of 8 batches: 4.344870507717133.
[ Mon Oct 21 19:10:17 2024 ] 	Top1: 3.30%
[ Mon Oct 21 19:10:17 2024 ] 	Top5: 14.10%
[ Mon Oct 21 19:10:17 2024 ] Training epoch: 2
[ Tue Oct 22 07:41:29 2024 ] using warm up, epoch: 5
[ Tue Oct 22 07:41:30 2024 ] Parameters:
{'work_dir': './mixformer_joint/work_dir', 'model_saved_name': './mixformer_joint/runs', 'config': './config_mixformer/mixformer_joint_train.yaml', 'device': 0, 'phase': 'train', 'save_score': True, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'dataset': 'datasets.dataset.UavDataset', 'num_workers': 0, 'train_data_args': {'data_path': './data/train_joint.npy', 'label_path': './data/train_label.npy', 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'debug': False, 'use_mmap': True, 'random_rot': False, 'p_interval': [0.5, 1], 'd': 2}, 'val_data_args': {'data_path': './data/test_A_joint.npy', 'label_path': './data/test_A_label.npy', 'debug': False, 'window_size': 64, 'p_interval': [0.95], 'd': 2}, 'test_data_args': {}, 'model': 'model.ske_mixf.Model', 'model_args': {'num_class': 155, 'num_point': 17, 'num_person': 2, 'graph': 'graph.uav.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'label_smoothing': 0.0, 'ignore_weights': [], 'base_lr': 0.2, 'step': [20, 40, 60], 'nesterov': True, 'optimizer': 'SGD', 'batch_size': 32, 'val_batch_size': 256, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'lr_decay_rate': 0.1, 'weight_decay': 0.0005, 'only_train_part': False, 'only_train_epoch': 0, 'warm_up_epoch': 5}

[ Tue Oct 22 07:41:30 2024 ] Training epoch: 1
[ Tue Oct 22 07:51:03 2024 ] 	Mean training loss: 5.0042.
[ Tue Oct 22 07:51:03 2024 ] Eval epoch: 1
[ Tue Oct 22 07:51:40 2024 ] 	Mean val loss of 8 batches: 4.344870507717133.
[ Tue Oct 22 07:51:40 2024 ] 	Top1: 3.30%
[ Tue Oct 22 07:51:40 2024 ] 	Top5: 14.10%
[ Tue Oct 22 07:51:40 2024 ] Training epoch: 2
[ Tue Oct 22 08:01:09 2024 ] 	Mean training loss: 4.1844.
[ Tue Oct 22 08:01:09 2024 ] Eval epoch: 2
[ Tue Oct 22 08:01:42 2024 ] 	Mean val loss of 8 batches: 3.657825291156769.
[ Tue Oct 22 08:01:42 2024 ] 	Top1: 7.55%
[ Tue Oct 22 08:01:42 2024 ] 	Top5: 33.95%
[ Tue Oct 22 08:01:42 2024 ] Training epoch: 3
[ Tue Oct 22 08:11:04 2024 ] 	Mean training loss: 3.7033.
[ Tue Oct 22 08:11:04 2024 ] Eval epoch: 3
[ Tue Oct 22 08:11:37 2024 ] 	Mean val loss of 8 batches: 3.354818195104599.
[ Tue Oct 22 08:11:37 2024 ] 	Top1: 14.80%
[ Tue Oct 22 08:11:37 2024 ] 	Top5: 44.75%
[ Tue Oct 22 08:11:37 2024 ] Training epoch: 4
[ Tue Oct 22 08:21:00 2024 ] 	Mean training loss: 3.3801.
[ Tue Oct 22 08:21:00 2024 ] Eval epoch: 4
[ Tue Oct 22 08:21:33 2024 ] 	Mean val loss of 8 batches: 2.9898739755153656.
[ Tue Oct 22 08:21:33 2024 ] 	Top1: 19.20%
[ Tue Oct 22 08:21:33 2024 ] 	Top5: 55.35%
[ Tue Oct 22 08:21:33 2024 ] Training epoch: 5
[ Tue Oct 22 08:30:58 2024 ] 	Mean training loss: 3.2714.
[ Tue Oct 22 08:30:58 2024 ] Eval epoch: 5
[ Tue Oct 22 08:31:32 2024 ] 	Mean val loss of 8 batches: 2.7894099354743958.
[ Tue Oct 22 08:31:32 2024 ] 	Top1: 24.45%
[ Tue Oct 22 08:31:32 2024 ] 	Top5: 63.10%
[ Tue Oct 22 08:31:32 2024 ] Training epoch: 6
[ Tue Oct 22 08:40:57 2024 ] 	Mean training loss: 3.1430.
[ Tue Oct 22 08:40:57 2024 ] Eval epoch: 6
[ Tue Oct 22 08:41:30 2024 ] 	Mean val loss of 8 batches: 2.9590212404727936.
[ Tue Oct 22 08:41:30 2024 ] 	Top1: 24.30%
[ Tue Oct 22 08:41:30 2024 ] 	Top5: 59.50%
[ Tue Oct 22 08:41:30 2024 ] Training epoch: 7
[ Tue Oct 22 08:50:55 2024 ] 	Mean training loss: 3.0560.
[ Tue Oct 22 08:50:55 2024 ] Eval epoch: 7
[ Tue Oct 22 08:51:30 2024 ] 	Mean val loss of 8 batches: 2.6633107364177704.
[ Tue Oct 22 08:51:30 2024 ] 	Top1: 26.75%
[ Tue Oct 22 08:51:30 2024 ] 	Top5: 66.05%
[ Tue Oct 22 08:51:30 2024 ] Training epoch: 8
[ Tue Oct 22 09:00:53 2024 ] 	Mean training loss: 2.9905.
[ Tue Oct 22 09:00:53 2024 ] Eval epoch: 8
[ Tue Oct 22 09:01:27 2024 ] 	Mean val loss of 8 batches: 2.600719541311264.
[ Tue Oct 22 09:01:27 2024 ] 	Top1: 29.95%
[ Tue Oct 22 09:01:27 2024 ] 	Top5: 66.45%
[ Tue Oct 22 09:01:27 2024 ] Training epoch: 9
[ Tue Oct 22 09:10:55 2024 ] 	Mean training loss: 2.9120.
[ Tue Oct 22 09:10:55 2024 ] Eval epoch: 9
[ Tue Oct 22 09:11:29 2024 ] 	Mean val loss of 8 batches: 2.506170004606247.
[ Tue Oct 22 09:11:29 2024 ] 	Top1: 30.10%
[ Tue Oct 22 09:11:29 2024 ] 	Top5: 69.55%
[ Tue Oct 22 09:11:29 2024 ] Training epoch: 10
[ Tue Oct 22 09:20:50 2024 ] 	Mean training loss: 2.8785.
[ Tue Oct 22 09:20:50 2024 ] Eval epoch: 10
[ Tue Oct 22 09:21:23 2024 ] 	Mean val loss of 8 batches: 2.9401716589927673.
[ Tue Oct 22 09:21:23 2024 ] 	Top1: 26.65%
[ Tue Oct 22 09:21:23 2024 ] 	Top5: 62.65%
[ Tue Oct 22 09:21:23 2024 ] Training epoch: 11
[ Tue Oct 22 09:30:50 2024 ] 	Mean training loss: 2.8344.
[ Tue Oct 22 09:30:50 2024 ] Eval epoch: 11
[ Tue Oct 22 09:31:25 2024 ] 	Mean val loss of 8 batches: 2.49320986866951.
[ Tue Oct 22 09:31:25 2024 ] 	Top1: 33.40%
[ Tue Oct 22 09:31:25 2024 ] 	Top5: 69.85%
[ Tue Oct 22 09:31:25 2024 ] Training epoch: 12
[ Tue Oct 22 09:40:49 2024 ] 	Mean training loss: 2.7991.
[ Tue Oct 22 09:40:49 2024 ] Eval epoch: 12
[ Tue Oct 22 09:41:23 2024 ] 	Mean val loss of 8 batches: 2.4398301541805267.
[ Tue Oct 22 09:41:23 2024 ] 	Top1: 31.10%
[ Tue Oct 22 09:41:23 2024 ] 	Top5: 71.05%
[ Tue Oct 22 09:41:23 2024 ] Training epoch: 13
[ Tue Oct 22 09:50:56 2024 ] 	Mean training loss: 2.7879.
[ Tue Oct 22 09:50:57 2024 ] Eval epoch: 13
[ Tue Oct 22 09:51:30 2024 ] 	Mean val loss of 8 batches: 2.4126954078674316.
[ Tue Oct 22 09:51:30 2024 ] 	Top1: 34.45%
[ Tue Oct 22 09:51:30 2024 ] 	Top5: 71.35%
[ Tue Oct 22 09:51:30 2024 ] Training epoch: 14
[ Tue Oct 22 10:00:58 2024 ] 	Mean training loss: 2.7528.
[ Tue Oct 22 10:00:58 2024 ] Eval epoch: 14
[ Tue Oct 22 10:01:31 2024 ] 	Mean val loss of 8 batches: 6.235362708568573.
[ Tue Oct 22 10:01:31 2024 ] 	Top1: 5.80%
[ Tue Oct 22 10:01:31 2024 ] 	Top5: 17.65%
[ Tue Oct 22 10:01:31 2024 ] Training epoch: 15
[ Tue Oct 22 10:10:56 2024 ] 	Mean training loss: 2.7333.
[ Tue Oct 22 10:10:56 2024 ] Eval epoch: 15
[ Tue Oct 22 10:11:29 2024 ] 	Mean val loss of 8 batches: 2.4770703315734863.
[ Tue Oct 22 10:11:30 2024 ] 	Top1: 34.40%
[ Tue Oct 22 10:11:30 2024 ] 	Top5: 69.50%
[ Tue Oct 22 10:11:30 2024 ] Training epoch: 16
[ Tue Oct 22 10:20:57 2024 ] 	Mean training loss: 2.7215.
[ Tue Oct 22 10:20:57 2024 ] Eval epoch: 16
[ Tue Oct 22 10:21:30 2024 ] 	Mean val loss of 8 batches: 2.7556413114070892.
[ Tue Oct 22 10:21:30 2024 ] 	Top1: 28.80%
[ Tue Oct 22 10:21:30 2024 ] 	Top5: 64.80%
[ Tue Oct 22 10:21:30 2024 ] Training epoch: 17
[ Tue Oct 22 10:30:54 2024 ] 	Mean training loss: 2.7257.
[ Tue Oct 22 10:30:54 2024 ] Eval epoch: 17
[ Tue Oct 22 10:31:28 2024 ] 	Mean val loss of 8 batches: 2.3724233508110046.
[ Tue Oct 22 10:31:28 2024 ] 	Top1: 36.90%
[ Tue Oct 22 10:31:28 2024 ] 	Top5: 75.00%
[ Tue Oct 22 10:31:28 2024 ] Training epoch: 18
[ Tue Oct 22 10:40:54 2024 ] 	Mean training loss: 2.7064.
[ Tue Oct 22 10:40:54 2024 ] Eval epoch: 18
[ Tue Oct 22 10:41:28 2024 ] 	Mean val loss of 8 batches: 2.2058102935552597.
[ Tue Oct 22 10:41:28 2024 ] 	Top1: 39.05%
[ Tue Oct 22 10:41:28 2024 ] 	Top5: 76.50%
[ Tue Oct 22 10:41:28 2024 ] Training epoch: 19
[ Tue Oct 22 10:50:55 2024 ] 	Mean training loss: 2.6933.
[ Tue Oct 22 10:50:55 2024 ] Eval epoch: 19
[ Tue Oct 22 10:51:29 2024 ] 	Mean val loss of 8 batches: 2.170788034796715.
[ Tue Oct 22 10:51:29 2024 ] 	Top1: 39.15%
[ Tue Oct 22 10:51:29 2024 ] 	Top5: 76.40%
[ Tue Oct 22 10:51:29 2024 ] Training epoch: 20
[ Tue Oct 22 11:00:57 2024 ] 	Mean training loss: 2.6857.
[ Tue Oct 22 11:00:57 2024 ] Eval epoch: 20
[ Tue Oct 22 11:01:30 2024 ] 	Mean val loss of 8 batches: 6.700820744037628.
[ Tue Oct 22 11:01:30 2024 ] 	Top1: 11.15%
[ Tue Oct 22 11:01:30 2024 ] 	Top5: 36.20%
[ Tue Oct 22 11:01:30 2024 ] Training epoch: 21
[ Tue Oct 22 11:10:57 2024 ] 	Mean training loss: 2.1663.
[ Tue Oct 22 11:10:57 2024 ] Eval epoch: 21
[ Tue Oct 22 11:11:31 2024 ] 	Mean val loss of 8 batches: 1.423137865960598.
[ Tue Oct 22 11:11:31 2024 ] 	Top1: 58.45%
[ Tue Oct 22 11:11:31 2024 ] 	Top5: 88.20%
[ Tue Oct 22 11:11:31 2024 ] Training epoch: 22
[ Tue Oct 22 11:20:57 2024 ] 	Mean training loss: 2.0246.
[ Tue Oct 22 11:20:57 2024 ] Eval epoch: 22
[ Tue Oct 22 11:21:31 2024 ] 	Mean val loss of 8 batches: 1.3796541839838028.
[ Tue Oct 22 11:21:31 2024 ] 	Top1: 58.20%
[ Tue Oct 22 11:21:31 2024 ] 	Top5: 89.75%
[ Tue Oct 22 11:21:31 2024 ] Training epoch: 23
[ Tue Oct 22 11:30:59 2024 ] 	Mean training loss: 1.9643.
[ Tue Oct 22 11:30:59 2024 ] Eval epoch: 23
[ Tue Oct 22 11:31:33 2024 ] 	Mean val loss of 8 batches: 1.3717286884784698.
[ Tue Oct 22 11:31:33 2024 ] 	Top1: 58.25%
[ Tue Oct 22 11:31:33 2024 ] 	Top5: 89.35%
[ Tue Oct 22 11:31:33 2024 ] Training epoch: 24
[ Tue Oct 22 11:41:00 2024 ] 	Mean training loss: 1.9347.
[ Tue Oct 22 11:41:00 2024 ] Eval epoch: 24
[ Tue Oct 22 11:41:33 2024 ] 	Mean val loss of 8 batches: 1.354522705078125.
[ Tue Oct 22 11:41:33 2024 ] 	Top1: 58.45%
[ Tue Oct 22 11:41:33 2024 ] 	Top5: 90.50%
[ Tue Oct 22 11:41:33 2024 ] Training epoch: 25
[ Tue Oct 22 11:51:01 2024 ] 	Mean training loss: 1.9054.
[ Tue Oct 22 11:51:01 2024 ] Eval epoch: 25
[ Tue Oct 22 11:51:34 2024 ] 	Mean val loss of 8 batches: 1.3926984518766403.
[ Tue Oct 22 11:51:34 2024 ] 	Top1: 57.90%
[ Tue Oct 22 11:51:34 2024 ] 	Top5: 90.10%
[ Tue Oct 22 11:51:34 2024 ] Training epoch: 26
[ Tue Oct 22 12:01:00 2024 ] 	Mean training loss: 1.8832.
[ Tue Oct 22 12:01:00 2024 ] Eval epoch: 26
[ Tue Oct 22 12:01:34 2024 ] 	Mean val loss of 8 batches: 1.3623988032341003.
[ Tue Oct 22 12:01:34 2024 ] 	Top1: 59.00%
[ Tue Oct 22 12:01:34 2024 ] 	Top5: 88.80%
[ Tue Oct 22 12:01:34 2024 ] Training epoch: 27
[ Tue Oct 22 12:10:59 2024 ] 	Mean training loss: 1.8631.
[ Tue Oct 22 12:10:59 2024 ] Eval epoch: 27
[ Tue Oct 22 12:11:32 2024 ] 	Mean val loss of 8 batches: 1.33986334502697.
[ Tue Oct 22 12:11:32 2024 ] 	Top1: 59.80%
[ Tue Oct 22 12:11:32 2024 ] 	Top5: 90.55%
[ Tue Oct 22 12:11:32 2024 ] Training epoch: 28
[ Tue Oct 22 12:21:00 2024 ] 	Mean training loss: 1.8573.
[ Tue Oct 22 12:21:00 2024 ] Eval epoch: 28
[ Tue Oct 22 12:21:34 2024 ] 	Mean val loss of 8 batches: 1.4005057960748672.
[ Tue Oct 22 12:21:34 2024 ] 	Top1: 57.50%
[ Tue Oct 22 12:21:34 2024 ] 	Top5: 89.70%
[ Tue Oct 22 12:21:34 2024 ] Training epoch: 29
[ Tue Oct 22 12:31:02 2024 ] 	Mean training loss: 1.8440.
[ Tue Oct 22 12:31:02 2024 ] Eval epoch: 29
[ Tue Oct 22 12:31:36 2024 ] 	Mean val loss of 8 batches: 1.3662267997860909.
[ Tue Oct 22 12:31:36 2024 ] 	Top1: 59.95%
[ Tue Oct 22 12:31:36 2024 ] 	Top5: 89.60%
[ Tue Oct 22 12:31:36 2024 ] Training epoch: 30
[ Tue Oct 22 12:41:00 2024 ] 	Mean training loss: 1.8201.
[ Tue Oct 22 12:41:00 2024 ] Eval epoch: 30
[ Tue Oct 22 12:41:34 2024 ] 	Mean val loss of 8 batches: 1.4015383422374725.
[ Tue Oct 22 12:41:34 2024 ] 	Top1: 58.45%
[ Tue Oct 22 12:41:34 2024 ] 	Top5: 88.80%
[ Tue Oct 22 12:41:34 2024 ] Training epoch: 31
[ Tue Oct 22 12:51:01 2024 ] 	Mean training loss: 1.8205.
[ Tue Oct 22 12:51:01 2024 ] Eval epoch: 31
[ Tue Oct 22 12:51:34 2024 ] 	Mean val loss of 8 batches: 1.425063133239746.
[ Tue Oct 22 12:51:34 2024 ] 	Top1: 58.45%
[ Tue Oct 22 12:51:34 2024 ] 	Top5: 88.80%
[ Tue Oct 22 12:51:34 2024 ] Training epoch: 32
[ Tue Oct 22 13:01:02 2024 ] 	Mean training loss: 1.8081.
[ Tue Oct 22 13:01:02 2024 ] Eval epoch: 32
[ Tue Oct 22 13:01:36 2024 ] 	Mean val loss of 8 batches: 1.38028222322464.
[ Tue Oct 22 13:01:36 2024 ] 	Top1: 60.25%
[ Tue Oct 22 13:01:36 2024 ] 	Top5: 89.00%
[ Tue Oct 22 13:01:36 2024 ] Training epoch: 33
[ Tue Oct 22 13:11:03 2024 ] 	Mean training loss: 1.7926.
[ Tue Oct 22 13:11:03 2024 ] Eval epoch: 33
[ Tue Oct 22 13:11:36 2024 ] 	Mean val loss of 8 batches: 1.3506233468651772.
[ Tue Oct 22 13:11:36 2024 ] 	Top1: 59.70%
[ Tue Oct 22 13:11:36 2024 ] 	Top5: 89.70%
[ Tue Oct 22 13:11:36 2024 ] Training epoch: 34
[ Tue Oct 22 13:21:05 2024 ] 	Mean training loss: 1.7897.
[ Tue Oct 22 13:21:05 2024 ] Eval epoch: 34
[ Tue Oct 22 13:21:39 2024 ] 	Mean val loss of 8 batches: 1.3736205026507378.
[ Tue Oct 22 13:21:39 2024 ] 	Top1: 60.25%
[ Tue Oct 22 13:21:39 2024 ] 	Top5: 89.25%
[ Tue Oct 22 13:21:39 2024 ] Training epoch: 35
[ Tue Oct 22 13:31:07 2024 ] 	Mean training loss: 1.7765.
[ Tue Oct 22 13:31:07 2024 ] Eval epoch: 35
[ Tue Oct 22 13:31:40 2024 ] 	Mean val loss of 8 batches: 1.325559750199318.
[ Tue Oct 22 13:31:40 2024 ] 	Top1: 61.25%
[ Tue Oct 22 13:31:40 2024 ] 	Top5: 89.95%
[ Tue Oct 22 13:31:40 2024 ] Training epoch: 36
[ Tue Oct 22 13:41:07 2024 ] 	Mean training loss: 1.7656.
[ Tue Oct 22 13:41:07 2024 ] Eval epoch: 36
[ Tue Oct 22 13:42:00 2024 ] 	Mean val loss of 8 batches: 1.3665880113840103.
[ Tue Oct 22 13:42:00 2024 ] 	Top1: 60.05%
[ Tue Oct 22 13:42:00 2024 ] 	Top5: 89.00%
[ Tue Oct 22 13:42:00 2024 ] Training epoch: 37
[ Tue Oct 22 13:51:26 2024 ] 	Mean training loss: 1.7649.
[ Tue Oct 22 13:51:26 2024 ] Eval epoch: 37
[ Tue Oct 22 13:52:20 2024 ] 	Mean val loss of 8 batches: 1.318924941122532.
[ Tue Oct 22 13:52:20 2024 ] 	Top1: 60.55%
[ Tue Oct 22 13:52:20 2024 ] 	Top5: 90.00%
[ Tue Oct 22 13:52:20 2024 ] Training epoch: 38
[ Tue Oct 22 14:01:49 2024 ] 	Mean training loss: 1.7406.
[ Tue Oct 22 14:01:49 2024 ] Eval epoch: 38
[ Tue Oct 22 14:02:43 2024 ] 	Mean val loss of 8 batches: 1.3110260739922523.
[ Tue Oct 22 14:02:43 2024 ] 	Top1: 61.40%
[ Tue Oct 22 14:02:43 2024 ] 	Top5: 90.30%
[ Tue Oct 22 14:02:43 2024 ] Training epoch: 39
[ Tue Oct 22 14:12:11 2024 ] 	Mean training loss: 1.7395.
[ Tue Oct 22 14:12:11 2024 ] Eval epoch: 39
[ Tue Oct 22 14:13:05 2024 ] 	Mean val loss of 8 batches: 1.4272316172719002.
[ Tue Oct 22 14:13:05 2024 ] 	Top1: 58.45%
[ Tue Oct 22 14:13:05 2024 ] 	Top5: 88.55%
[ Tue Oct 22 14:13:05 2024 ] Training epoch: 40
[ Tue Oct 22 14:22:31 2024 ] 	Mean training loss: 1.7367.
[ Tue Oct 22 14:22:31 2024 ] Eval epoch: 40
[ Tue Oct 22 14:23:25 2024 ] 	Mean val loss of 8 batches: 1.3138666674494743.
[ Tue Oct 22 14:23:25 2024 ] 	Top1: 61.85%
[ Tue Oct 22 14:23:25 2024 ] 	Top5: 90.55%
[ Tue Oct 22 14:23:25 2024 ] Training epoch: 41
[ Tue Oct 22 14:32:51 2024 ] 	Mean training loss: 1.5065.
[ Tue Oct 22 14:32:51 2024 ] Eval epoch: 41
[ Tue Oct 22 14:33:45 2024 ] 	Mean val loss of 8 batches: 1.1415463387966156.
[ Tue Oct 22 14:33:45 2024 ] 	Top1: 66.35%
[ Tue Oct 22 14:33:45 2024 ] 	Top5: 91.90%
[ Tue Oct 22 14:33:45 2024 ] Training epoch: 42
[ Tue Oct 22 14:43:11 2024 ] 	Mean training loss: 1.4324.
[ Tue Oct 22 14:43:11 2024 ] Eval epoch: 42
[ Tue Oct 22 14:44:04 2024 ] 	Mean val loss of 8 batches: 1.1392779797315598.
[ Tue Oct 22 14:44:04 2024 ] 	Top1: 66.45%
[ Tue Oct 22 14:44:04 2024 ] 	Top5: 91.70%
[ Tue Oct 22 14:44:04 2024 ] Training epoch: 43
[ Tue Oct 22 14:53:35 2024 ] 	Mean training loss: 1.4020.
[ Tue Oct 22 14:53:35 2024 ] Eval epoch: 43
[ Tue Oct 22 14:54:29 2024 ] 	Mean val loss of 8 batches: 1.1141509637236595.
[ Tue Oct 22 14:54:29 2024 ] 	Top1: 67.45%
[ Tue Oct 22 14:54:29 2024 ] 	Top5: 92.10%
[ Tue Oct 22 14:54:29 2024 ] Training epoch: 44
[ Tue Oct 22 15:03:55 2024 ] 	Mean training loss: 1.3739.
[ Tue Oct 22 15:03:56 2024 ] Eval epoch: 44
[ Tue Oct 22 15:04:51 2024 ] 	Mean val loss of 8 batches: 1.1272452548146248.
[ Tue Oct 22 15:04:51 2024 ] 	Top1: 67.40%
[ Tue Oct 22 15:04:51 2024 ] 	Top5: 91.75%
[ Tue Oct 22 15:04:51 2024 ] Training epoch: 45
[ Tue Oct 22 15:14:17 2024 ] 	Mean training loss: 1.3600.
[ Tue Oct 22 15:14:17 2024 ] Eval epoch: 45
[ Tue Oct 22 15:15:11 2024 ] 	Mean val loss of 8 batches: 1.111165665090084.
[ Tue Oct 22 15:15:11 2024 ] 	Top1: 67.75%
[ Tue Oct 22 15:15:11 2024 ] 	Top5: 92.65%
[ Tue Oct 22 15:15:11 2024 ] Training epoch: 46
[ Tue Oct 22 15:24:37 2024 ] 	Mean training loss: 1.3405.
[ Tue Oct 22 15:24:37 2024 ] Eval epoch: 46
[ Tue Oct 22 15:25:32 2024 ] 	Mean val loss of 8 batches: 1.1190343797206879.
[ Tue Oct 22 15:25:32 2024 ] 	Top1: 67.40%
[ Tue Oct 22 15:25:32 2024 ] 	Top5: 92.40%
[ Tue Oct 22 15:25:32 2024 ] Training epoch: 47
[ Tue Oct 22 15:34:59 2024 ] 	Mean training loss: 1.3317.
[ Tue Oct 22 15:34:59 2024 ] Eval epoch: 47
[ Tue Oct 22 15:35:51 2024 ] 	Mean val loss of 8 batches: 1.143349215388298.
[ Tue Oct 22 15:35:52 2024 ] 	Top1: 67.75%
[ Tue Oct 22 15:35:52 2024 ] 	Top5: 92.10%
[ Tue Oct 22 15:35:52 2024 ] Training epoch: 48
[ Tue Oct 22 15:45:21 2024 ] 	Mean training loss: 1.3127.
[ Tue Oct 22 15:45:21 2024 ] Eval epoch: 48
[ Tue Oct 22 15:46:14 2024 ] 	Mean val loss of 8 batches: 1.093371406197548.
[ Tue Oct 22 15:46:14 2024 ] 	Top1: 67.35%
[ Tue Oct 22 15:46:14 2024 ] 	Top5: 92.30%
[ Tue Oct 22 15:46:14 2024 ] Training epoch: 49
[ Tue Oct 22 15:55:42 2024 ] 	Mean training loss: 1.2948.
[ Tue Oct 22 15:55:42 2024 ] Eval epoch: 49
[ Tue Oct 22 15:56:36 2024 ] 	Mean val loss of 8 batches: 1.1428437903523445.
[ Tue Oct 22 15:56:36 2024 ] 	Top1: 66.85%
[ Tue Oct 22 15:56:36 2024 ] 	Top5: 92.20%
[ Tue Oct 22 15:56:36 2024 ] Training epoch: 50
[ Tue Oct 22 16:06:03 2024 ] 	Mean training loss: 1.2881.
[ Tue Oct 22 16:06:03 2024 ] Eval epoch: 50
[ Tue Oct 22 16:06:56 2024 ] 	Mean val loss of 8 batches: 1.1134880110621452.
[ Tue Oct 22 16:06:56 2024 ] 	Top1: 67.90%
[ Tue Oct 22 16:06:56 2024 ] 	Top5: 92.75%
[ Tue Oct 22 16:06:56 2024 ] Training epoch: 51
[ Tue Oct 22 16:16:11 2024 ] 	Mean training loss: 1.2735.
[ Tue Oct 22 16:16:11 2024 ] Eval epoch: 51
[ Tue Oct 22 16:17:02 2024 ] 	Mean val loss of 8 batches: 1.110841028392315.
[ Tue Oct 22 16:17:02 2024 ] 	Top1: 67.50%
[ Tue Oct 22 16:17:02 2024 ] 	Top5: 92.15%
[ Tue Oct 22 16:17:02 2024 ] Training epoch: 52
[ Tue Oct 22 16:26:16 2024 ] 	Mean training loss: 1.2733.
[ Tue Oct 22 16:26:17 2024 ] Eval epoch: 52
[ Tue Oct 22 16:27:09 2024 ] 	Mean val loss of 8 batches: 1.129438504576683.
[ Tue Oct 22 16:27:09 2024 ] 	Top1: 67.95%
[ Tue Oct 22 16:27:09 2024 ] 	Top5: 91.95%
[ Tue Oct 22 16:27:09 2024 ] Training epoch: 53
[ Tue Oct 22 16:36:27 2024 ] 	Mean training loss: 1.2549.
[ Tue Oct 22 16:36:27 2024 ] Eval epoch: 53
[ Tue Oct 22 16:37:20 2024 ] 	Mean val loss of 8 batches: 1.139553464949131.
[ Tue Oct 22 16:37:20 2024 ] 	Top1: 66.75%
[ Tue Oct 22 16:37:20 2024 ] 	Top5: 92.25%
[ Tue Oct 22 16:37:20 2024 ] Training epoch: 54
[ Tue Oct 22 16:46:48 2024 ] 	Mean training loss: 1.2370.
[ Tue Oct 22 16:46:48 2024 ] Eval epoch: 54
[ Tue Oct 22 16:47:42 2024 ] 	Mean val loss of 8 batches: 1.1140937954187393.
[ Tue Oct 22 16:47:42 2024 ] 	Top1: 68.00%
[ Tue Oct 22 16:47:42 2024 ] 	Top5: 92.40%
[ Tue Oct 22 16:47:42 2024 ] Training epoch: 55
[ Tue Oct 22 16:57:07 2024 ] 	Mean training loss: 1.2396.
[ Tue Oct 22 16:57:07 2024 ] Eval epoch: 55
[ Tue Oct 22 16:58:01 2024 ] 	Mean val loss of 8 batches: 1.1314799189567566.
[ Tue Oct 22 16:58:01 2024 ] 	Top1: 67.30%
[ Tue Oct 22 16:58:01 2024 ] 	Top5: 92.10%
[ Tue Oct 22 16:58:01 2024 ] Training epoch: 56
[ Tue Oct 22 17:07:30 2024 ] 	Mean training loss: 1.2189.
[ Tue Oct 22 17:07:30 2024 ] Eval epoch: 56
[ Tue Oct 22 17:08:24 2024 ] 	Mean val loss of 8 batches: 1.1156575605273247.
[ Tue Oct 22 17:08:24 2024 ] 	Top1: 67.60%
[ Tue Oct 22 17:08:24 2024 ] 	Top5: 92.40%
[ Tue Oct 22 17:08:24 2024 ] Training epoch: 57
[ Tue Oct 22 17:17:51 2024 ] 	Mean training loss: 1.2095.
[ Tue Oct 22 17:17:51 2024 ] Eval epoch: 57
[ Tue Oct 22 17:18:45 2024 ] 	Mean val loss of 8 batches: 1.1407206431031227.
[ Tue Oct 22 17:18:45 2024 ] 	Top1: 67.50%
[ Tue Oct 22 17:18:45 2024 ] 	Top5: 92.00%
[ Tue Oct 22 17:18:45 2024 ] Training epoch: 58
[ Tue Oct 22 17:28:12 2024 ] 	Mean training loss: 1.1945.
[ Tue Oct 22 17:28:12 2024 ] Eval epoch: 58
[ Tue Oct 22 17:29:06 2024 ] 	Mean val loss of 8 batches: 1.128289371728897.
[ Tue Oct 22 17:29:06 2024 ] 	Top1: 67.85%
[ Tue Oct 22 17:29:06 2024 ] 	Top5: 92.55%
[ Tue Oct 22 17:29:06 2024 ] Training epoch: 59
[ Tue Oct 22 17:38:34 2024 ] 	Mean training loss: 1.1788.
[ Tue Oct 22 17:38:34 2024 ] Eval epoch: 59
[ Tue Oct 22 17:39:29 2024 ] 	Mean val loss of 8 batches: 1.1490096598863602.
[ Tue Oct 22 17:39:29 2024 ] 	Top1: 67.80%
[ Tue Oct 22 17:39:29 2024 ] 	Top5: 91.65%
[ Tue Oct 22 17:39:29 2024 ] Training epoch: 60
[ Tue Oct 22 17:48:55 2024 ] 	Mean training loss: 1.1775.
[ Tue Oct 22 17:48:55 2024 ] Eval epoch: 60
[ Tue Oct 22 17:49:49 2024 ] 	Mean val loss of 8 batches: 1.1155149787664413.
[ Tue Oct 22 17:49:49 2024 ] 	Top1: 68.00%
[ Tue Oct 22 17:49:49 2024 ] 	Top5: 92.30%
[ Tue Oct 22 17:49:49 2024 ] Training epoch: 61
[ Tue Oct 22 17:59:18 2024 ] 	Mean training loss: 1.1240.
[ Tue Oct 22 17:59:18 2024 ] Eval epoch: 61
[ Tue Oct 22 18:00:12 2024 ] 	Mean val loss of 8 batches: 1.1186265349388123.
[ Tue Oct 22 18:00:12 2024 ] 	Top1: 68.10%
[ Tue Oct 22 18:00:12 2024 ] 	Top5: 92.10%
